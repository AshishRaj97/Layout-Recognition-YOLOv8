# ğŸ“ YOLOv8 Layout Recognition for Historical Documents  

This project utilizes **YOLOv8** for **Layout Organization Recognition** in **historical scanned documents**.  
The model detects **text regions**, including **headings, main text, authors, and drop caps**, while ignoring embellishments. 

---

## ğŸš€ Features  

âœ” **Dataset:** Custom dataset of **historical document images** with detailed annotations.  
âœ” **Model:** **YOLOv8m**, fine-tuned with custom **augmentation** & **hyperparameters**.  
âœ” **Training:** **180 epochs**, optimized learning rate, batch size, and augmentation techniques.  
âœ” **Evaluation:** Precision, Recall, **mAP@0.5**, **mAP@0.5:0.95**, and **training loss analysis**.  
âœ” **Inference:** Predicts layouts on **new document images** and **saves** structured outputs.  
âœ” **Visualization:** Training loss, **mAP trends, Precision-Recall curves, and Confusion Matrix**.  

---

## âš™ï¸ Requirements  

- **Python 3.7+**
- **GPU (Recommended): A Tesla T4 (used in Colab) or any NVIDIA GPU with at least 8GB VRAM for faster training.**  
- **Ultralytics YOLOv8**  
- **PyTorch, Pandas, Matplotlib, Pillow (PIL)**

## ğŸš€ Installation  

### 1ï¸âƒ£ Clone the Repository  
```bash
git clone https://github.com/AshishRaj97/Layout-Recognition-YOLOv8.git
```
### 2ï¸âƒ£ Install Required Packages
```bash
pip install ultralytics
pip install torch
pip install pandas matplotlib pillow
```

### ğŸ“œ Dataset & Model  
ğŸ”¹ **Dataset**: Scanned historical documents with varying layouts.  
ğŸ”¹ **Model**: Trained using **YOLOv8m**, **AdamW optimizer**, and **custom augmentations**.  

ğŸ“¥ **Download Dataset & YOLO Results:**  
- ğŸ“ [Dataset (Train, Test, Valid)](https://drive.google.com/drive/folders/1tvZZfsfFHPlLx26hQEDGcEnAJ6h9g0wm?usp=drive_link)  
- ğŸ“ [YOLO Results (Trained Weights & Predictions)](https://drive.google.com/drive/folders/1hjbZ72TodFKLEgVIRXIIpPbUUwb7eqom?usp=drive_link)  

## ğŸ¯ Model Performance  

ğŸ“Œ **Final Evaluation Metrics:**  

| **Metric**    | **Value**  |
|--------------|-----------|
| Precision    | 85.4%     |
| Recall       | 86.3%     |
| mAP@0.5      | 91.2%     |
| mAP@0.5:0.95 | 75.9%     |

ğŸ“Š **Training Loss & mAP Trends Over Epochs:**  

![download](https://github.com/user-attachments/assets/82e2b6ef-e2c8-4684-9735-b0061bd7f2b2)

ğŸ“ˆ **Precision-Recall Curve:**  

![download](https://github.com/user-attachments/assets/e3e92478-d896-4f30-a716-0806564cf981)

âœ… Successful Layout Recognition:

![d2869d59-2563-4794-80c4-a8d21063e2c1](https://github.com/user-attachments/assets/7aa4ef01-18a2-46fc-96cb-8b542b2b54f2)

## ğŸš€ Observations  
âœ” **Good model convergence** with minimal overfitting.  
âœ” **Improved recall & precision**, enhancing layout recognition accuracy.  
âœ” **Strong detection** of main text and drop caps, with minor misclassifications in headings and author labels.  
âœ” **mAP@0.5 = 91.2%** and **mAP@0.5:0.95 = 75.9%**, indicating reliable detection but scope for layout refinement.  

---

## ğŸ”„ Next Steps for Improvement  
âœ” **Expand dataset** (current: 52 images) and add more text variations.  
âœ” **Apply stronger augmentations** (rotation, shearing, perspective) to improve generalization.  
âœ” **Fine-tune confidence threshold & IoU ** for better text region segmentation.  
âœ” **Experiment with YOLOv8L or YOLOv8X** for improved feature extraction.  
âœ” **Implement OCR post-processing** to assess text extraction accuracy.  
âœ” **Optimize heading recognition & threshold settings** for enhanced classification.  

## ğŸ“œ License  
This project is licensed under the **MIT License**. See the [LICENSE](LICENSE) file for details.  

## ğŸ‘¨â€ğŸ’» Author  
ğŸ“Œ **Ashish Raj**  
ğŸ“§ [ar469492@gmail.com] | ğŸ–¥ï¸ [Your GitHub](https://github.com/your-username)  

ğŸ”¹ If you find this project useful, give it a â­ on GitHub! ğŸš€  
